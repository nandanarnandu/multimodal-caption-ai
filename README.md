# Multimodal AI Caption Matching

This project uses OpenAI's CLIP model to match images with the most suitable captions using cosine similarity.

## ðŸš€ How it Works
- You upload an image (e.g., a cup of tea)
- The model compares it with 70+ tea-themed captions
- It returns the top 5 most similar ones

## ðŸ”§ Tech Stack
- Python
- Hugging Face Transformers
- PyTorch
- Google Colab

## ðŸ“¦ How to Use
1. Open the notebook in Google Colab
2. Upload your image
3. Run the cells to get matching captions

## ðŸ“· Example Output
> Image: `tea.jpg`  
> Top Caption: `"Savor the moment of peace."`

---

Want to use this for other types of images? Just replace the caption list!

